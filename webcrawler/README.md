# ç®€æ˜“ç½‘ç»œçˆ¬è™« (Simple Web Crawler)

ä¸€ä¸ªæ¨¡å—åŒ–ã€å¯æ‰©å±•çš„ Python ç½‘ç»œçˆ¬è™«å®ç°ã€‚

## ğŸ“‹ åŠŸèƒ½ç‰¹æ€§

- **æ¨¡å—åŒ–æ¶æ„**: å„ç»„ä»¶ç‹¬ç«‹è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **URL è°ƒåº¦å™¨**: æ”¯æŒä¼˜å…ˆçº§é˜Ÿåˆ—å’Œç¤¼è²Œç­–ç•¥ï¼ˆPolitenessï¼‰
- **DNS ç¼“å­˜**: å‡å°‘ DNS æŸ¥è¯¢å»¶è¿Ÿ
- **åŒé‡å»é‡**: URL å»é‡ + å†…å®¹å»é‡ï¼ˆåŸºäºå¸ƒéš†è¿‡æ»¤å™¨ï¼‰
- **å¯æ‰©å±•æ¨¡å—**: æ”¯æŒæ’ä»¶åŒ–çš„æ‰©å±•æ¨¡å—
  - é“¾æ¥æå–å™¨ (Link Extractor)
  - å›¾ç‰‡ä¸‹è½½å™¨ (Image Downloader)
  - ç½‘é¡µç›‘æ§å™¨ (Web Monitor)
- **å¹¶å‘çˆ¬å–**: æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  seed URLs  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”Œâ”€â”€â”€â”€â”€â”‚URL Frontier â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
              â”‚            â”‚                                â”‚
              â”‚            â–¼                                â”‚
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
              â”‚     â”‚   HTML      â”‚â—„â”€â”€â”€â”€â”‚    DNS      â”‚    â”‚
              â”‚     â”‚ Downloader  â”‚     â”‚  Resolver   â”‚    â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
              â”‚            â”‚                                â”‚
              â”‚            â–¼                                â”‚
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
              â”‚     â”‚  Content    â”‚                         â”‚
              â”‚     â”‚   Parser    â”‚                         â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
              â”‚            â”‚                                â”‚
              â”‚            â–¼                                â”‚
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
              â”‚     â”‚Content Seen?â”‚â”€â”€Yesâ”€â”€â–ºä¸¢å¼ƒ            â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                         â”‚
              â”‚            â”‚No                              â”‚
              â”‚            â–¼                                â”‚
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
              â”‚     â”‚  Content    â”‚     â”‚Extension Module â”‚ â”‚
              â”‚     â”‚  Storage    â”‚     â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚â”‚PNG Downloader â”‚â”‚ â”‚
              â”‚                         â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚ â”‚
              â”‚                         â”‚â”‚Link Extractor â”‚â”‚ â”‚
              â”‚                         â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚ â”‚
              â”‚                         â”‚â”‚ Web Monitor   â”‚â”‚ â”‚
              â”‚                         â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
              â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
              â”‚                                  â”‚          â”‚
              â”‚                                  â–¼          â”‚
              â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
              â”‚                         â”‚ URL Filter  â”‚     â”‚
              â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
              â”‚                                â”‚            â”‚
              â”‚                                â–¼            â”‚
              â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
              â”‚                         â”‚  URL Seen?  â”‚     â”‚
              â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
              â”‚                                â”‚No          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ å®‰è£…

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd webcrawler

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# çˆ¬å–å•ä¸ªç½‘ç«™
python main.py --url https://example.com --max-pages 50

# ä»æ–‡ä»¶è¯»å–ç§å­ URL
python main.py --urls seed_urls.txt --max-depth 3

# è‡ªå®šä¹‰é…ç½®
python main.py --url https://example.com \
    --max-pages 100 \
    --max-depth 3 \
    --workers 10 \
    --delay 0.5 \
    --output ./my_data
```

### å‚æ•°è¯´æ˜

| å‚æ•° | ç®€å†™ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--url` | `-u` | - | è¦çˆ¬å–çš„å•ä¸ª URL |
| `--urls` | `-U` | - | åŒ…å«ç§å­ URL çš„æ–‡ä»¶ |
| `--max-pages` | `-p` | 100 | æœ€å¤§çˆ¬å–é¡µé¢æ•° |
| `--max-depth` | `-d` | 3 | æœ€å¤§çˆ¬å–æ·±åº¦ |
| `--workers` | `-w` | 5 | å¹¶å‘å·¥ä½œçº¿ç¨‹æ•° |
| `--delay` | - | 1.0 | åŒä¸€åŸŸåè¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ |
| `--timeout` | - | 10 | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |
| `--output` | `-o` | ./crawled_data | è¾“å‡ºç›®å½• |
| `--allowed-domains` | - | - | åªçˆ¬å–æŒ‡å®šåŸŸå |
| `--blocked-domains` | - | - | ä¸çˆ¬å–çš„åŸŸåé»‘åå• |
| `--no-images` | - | False | ä¸ä¸‹è½½å›¾ç‰‡ |
| `--no-monitor` | - | False | ç¦ç”¨ç½‘é¡µç›‘æ§ |
| `--user-agent` | - | SimpleCrawler/1.0 | è‡ªå®šä¹‰ User-Agent |

### ä»£ç ä¸­ä½¿ç”¨

```python
from config import CrawlerConfig
from crawler import WebCrawler

# åˆ›å»ºé…ç½®
config = CrawlerConfig(
    max_workers=5,
    max_depth=3,
    max_pages=100,
    request_delay=1.0
)

# åˆ›å»ºçˆ¬è™«
crawler = WebCrawler(config)

# æ·»åŠ ç§å­ URL
crawler.add_seed_urls([
    "https://example.com",
    "https://example.org"
])

# å¼€å§‹çˆ¬å–
stats = crawler.crawl()

# è·å–ç»Ÿè®¡ä¿¡æ¯
print(crawler.get_stats())
```

## ğŸ“ è¾“å‡ºç»“æ„

```
crawled_data/
â”œâ”€â”€ content/           # ç½‘é¡µå†…å®¹
â”‚   â”œâ”€â”€ example_com_abc123.html
â”‚   â””â”€â”€ ...
â”œâ”€â”€ images/            # ä¸‹è½½çš„å›¾ç‰‡
â”‚   â”œâ”€â”€ image_def456.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ meta/              # å…ƒæ•°æ®
â”‚   â”œâ”€â”€ url_history.jsonl    # URL å†å²
â”‚   â””â”€â”€ crawl_log.jsonl      # çˆ¬å–æ—¥å¿—
â””â”€â”€ monitor/           # ç›‘æ§æ•°æ®
    â”œâ”€â”€ latest_status.json   # æœ€æ–°çŠ¶æ€
    â””â”€â”€ history.jsonl        # çŠ¶æ€å†å²
```

## ğŸ§© æ¨¡å—è¯´æ˜

| æ¨¡å— | æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|------|
| é…ç½® | `config.py` | çˆ¬è™«é…ç½®ç®¡ç† |
| URL è°ƒåº¦å™¨ | `frontier.py` | URL é˜Ÿåˆ—å’Œä¼˜å…ˆçº§è°ƒåº¦ |
| DNS è§£æå™¨ | `dns_resolver.py` | DNS è§£æå’Œç¼“å­˜ |
| ä¸‹è½½å™¨ | `downloader.py` | HTTP è¯·æ±‚å’Œå†…å®¹ä¸‹è½½ |
| è§£æå™¨ | `parser.py` | HTML è§£æå’Œå†…å®¹æå– |
| å»é‡å™¨ | `dedup.py` | URL å’Œå†…å®¹å»é‡ |
| å­˜å‚¨ | `storage.py` | å†…å®¹å’Œå…ƒæ•°æ®å­˜å‚¨ |
| URL è¿‡æ»¤å™¨ | `url_filter.py` | URL è¿‡æ»¤å’ŒéªŒè¯ |
| æ‰©å±•æ¨¡å— | `extensions/` | å¯æ’æ‹”æ‰©å±•åŠŸèƒ½ |
| ä¸»æ§åˆ¶å™¨ | `crawler.py` | çˆ¬è™«æµç¨‹æ§åˆ¶ |

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **éµå®ˆ robots.txt**: æœ¬çˆ¬è™«ä»…ä¾›å­¦ä¹ ä½¿ç”¨ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·éµå®ˆç½‘ç«™çš„çˆ¬å–è§„åˆ™
2. **ç¤¼è²Œçˆ¬å–**: é»˜è®¤è®¾ç½®äº† 1 ç§’çš„è¯·æ±‚é—´éš”ï¼Œé¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè¿‡å¤§å‹åŠ›
3. **åˆæ³•ä½¿ç”¨**: è¯·ç¡®ä¿æ‚¨æœ‰æƒé™çˆ¬å–ç›®æ ‡ç½‘ç«™çš„å†…å®¹

## ğŸ“„ License

MIT License
